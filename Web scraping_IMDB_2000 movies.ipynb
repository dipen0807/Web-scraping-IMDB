{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data for over 2000 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning sources:\n",
    "# https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    "# https://www.dataquest.io/blog/web-scraping-beautifulsoup/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data for a single movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.imdb.com/search/title/?release_date=2017-01-01,2017-12-31&sort=num_votes,desc\"\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_containers = soup.find_all(\"div\", class_=\"lister-item mode-advanced\")\n",
    "\n",
    "print(type(movie_containers))\n",
    "print(len(movie_containers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll select only the first container, and extract, by turn, each item of interest:\n",
    "\n",
    "The name of the movie.\n",
    "The year of release.\n",
    "The IMDB rating.\n",
    "The Metascore.\n",
    "The number of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_containers[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = movie_containers[0].h3.a.text.strip()\n",
    "release_year = movie_containers[0].h3.find(\"span\", class_=\"lister-item-year\").text.strip()\n",
    "imdb_rating = float(movie_containers[0].strong.text)\n",
    "metascore = int(movie_containers[0].find(\"span\", class_=\"metascore favorable\").text)\n",
    "no_of_votes = movie_containers[0].find(\"span\", attrs = {\"name\": \"nv\"})[\"data-value\"]\n",
    "\n",
    "print(movie_name)\n",
    "print(release_year)\n",
    "print(imdb_rating)\n",
    "print(metascore)\n",
    "print(no_of_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_row = movie_containers[0].find(\"span\", attrs = {\"name\": \"nv\"})[\"data-value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store the scraped data\n",
    "\n",
    "names = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "\n",
    "for container in movie_containers:\n",
    "    \n",
    "    # if the movie has meta-score then and only then take that movie\n",
    "    if container.find(\"span\", class_=\"metascore favorable\") is not None:\n",
    "        \n",
    "        # movie names\n",
    "        names.append(container.h3.a.text.strip())\n",
    "        # release year\n",
    "        years.append(container.h3.find(\"span\", class_=\"lister-item-year\").text)\n",
    "        # imdb ratings\n",
    "        imdb_ratings.append(float(container.strong.text))\n",
    "        # meta-scores\n",
    "        metascores.append(int(container.find(\"span\", class_=\"metascore favorable\").text))\n",
    "        # number of votes\n",
    "        votes.append(int(container.find(\"span\", attrs = {\"name\": \"nv\"})[\"data-value\"]))\n",
    "        \n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Movie\": names,\n",
    "    \"Release year\": years,\n",
    "    \"IMDB ratings\": imdb_ratings,\n",
    "    \"Meta-scores\": metascores,\n",
    "    \"No of votes\": votes\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for extracting from multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the URL’s parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages\n",
    "starting_point = [\"1\", \"51\", \"101\", \"151\"]\n",
    "\n",
    "# years\n",
    "years_url = [str(i) for i in range(2016,2018)] # make it (2000, 2018) for more movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling the crawl-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "for _ in range(0,5):\n",
    "    print(\"Hello\")\n",
    "    sleep(randint(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring the loop as it’s still going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import clear_output\n",
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "req = 0\n",
    "\n",
    "for _ in range(5):\n",
    "    \n",
    "    # a request would go here.\n",
    "    req = req + 1\n",
    "    \n",
    "    sleep(randint(1,3))\n",
    "    \n",
    "    time_taken = time() - start_time\n",
    "    \n",
    "    print(\"Request: {}, Frequence: {} requests/s\".format(req, req/time_taken))\n",
    "    \n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "warn(\"warning simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecing everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redeclaring the lists to store data in\n",
    "names = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "\n",
    "# Preparing the monitoring of the loop\n",
    "start_time = time()\n",
    "req = 0\n",
    "\n",
    "for year in years_url:\n",
    "    \n",
    "    for star_point in starting_point:\n",
    "        \n",
    "        # Make a get request\n",
    "        url = \"https://www.imdb.com/search/title/?release_date=\" + year + \"&sort=num_votes,desc&start=\" + star_point\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(randint(3,8))\n",
    "        \n",
    "        # Monitor the requests\n",
    "        req = req + 1\n",
    "        taken_time = time() - start_time\n",
    "        \n",
    "        print(\"year: \", year, \"Starting point: \", star_point)\n",
    "        print('Request:{}; Frequency: {} requests/s'.format(req, req/taken_time))\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # Throw a warning for non-200 status codes\n",
    "        if response.status_code != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "            \n",
    "        # Break the loop if the number of requests is greater than expected\n",
    "        if req > 72:\n",
    "            warn('Number of requests was greater than expected.')\n",
    "            break\n",
    "            \n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        movie_containers = soup.find_all(\"div\", class_=\"lister-item mode-advanced\")\n",
    "        \n",
    "        for container in movie_containers:\n",
    "    \n",
    "            # if the movie has meta-score then and only then take that movie\n",
    "            if container.find(\"span\", class_=\"metascore favorable\") is not None:\n",
    "                \n",
    "                # movie names\n",
    "                names.append(container.h3.a.text.strip())\n",
    "                # release year\n",
    "                years.append(container.h3.find(\"span\", class_=\"lister-item-year\").text)\n",
    "                # imdb ratings\n",
    "                imdb_ratings.append(float(container.strong.text))\n",
    "                # meta-scores\n",
    "                metascores.append(int(container.find(\"span\", class_=\"metascore favorable\").text))\n",
    "                # number of votes\n",
    "                votes.append(int(container.find(\"span\", attrs = {\"name\": \"nv\"})[\"data-value\"]))\n",
    "        \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = pd.DataFrame({'Movie': names,\n",
    "'Release year': years,\n",
    "'IMDB rating': imdb_ratings,\n",
    "'Meta-score': metascores,\n",
    "'Number of votes': votes\n",
    "})\n",
    "\n",
    "print(movie_ratings.info())\n",
    "movie_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data before exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings[\"Release year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings[\"Release year\"] = movie_ratings[\"Release year\"].str[-5:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings[\"Release year\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.to_csv(\"IMDB_Movie ratings.csv\")\n",
    "\n",
    "print(\"Data exported to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
